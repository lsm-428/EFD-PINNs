import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import os
from datetime import datetime
from collections import defaultdict

class ModelPerformanceMonitor:
    """
    EWP-PINNæ¨¡å‹æ€§èƒ½ç›‘æ§ä¸è¯Šæ–­å·¥å…·
    æä¾›å…¨é¢çš„æ¨¡å‹æ€§èƒ½åˆ†æã€è¯Šæ–­å’Œå¯è§†åŒ–åŠŸèƒ½
    """
    
    def __init__(self, device='cpu', save_dir='./performance_reports'):
        """
        åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
        
        Args:
            device: è®¡ç®—è®¾å¤‡ (cpu æˆ– cuda)
            save_dir: æŠ¥å‘Šä¿å­˜ç›®å½•
        """
        self.device = device
        self.save_dir = save_dir
        self.metrics_history = defaultdict(list)
        self.diagnostic_results = {}
        self.current_stage = 0
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # è®¾ç½®å¯è§†åŒ–æ ·å¼
        plt.style.use('seaborn-v0_8-whitegrid')
        sns.set_palette("husl")
    
    def log_training_metrics(self, epoch, train_loss, val_loss, train_mae=None, val_mae=None,
                           physics_loss=None, data_loss=None, learning_rate=None):
        """
        è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡
        
        Args:
            epoch: å½“å‰è½®æ¬¡
            train_loss: è®­ç»ƒæŸå¤±
            val_loss: éªŒè¯æŸå¤±
            train_mae: è®­ç»ƒMAE (å¯é€‰)
            val_mae: éªŒè¯MAE (å¯é€‰)
            physics_loss: ç‰©ç†çº¦æŸæŸå¤± (å¯é€‰)
            data_loss: æ•°æ®æŸå¤± (å¯é€‰)
            learning_rate: å½“å‰å­¦ä¹ ç‡ (å¯é€‰)
        """
        self.metrics_history['epoch'].append(epoch)
        self.metrics_history['train_loss'].append(train_loss)
        self.metrics_history['val_loss'].append(val_loss)
        
        if train_mae is not None:
            self.metrics_history['train_mae'].append(train_mae)
        if val_mae is not None:
            self.metrics_history['val_mae'].append(val_mae)
        if physics_loss is not None:
            self.metrics_history['physics_loss'].append(physics_loss)
        if data_loss is not None:
            self.metrics_history['data_loss'].append(data_loss)
        if learning_rate is not None:
            self.metrics_history['learning_rate'].append(learning_rate)
    
    def start_training_stage(self, stage_name, stage_config):
        """
        å¼€å§‹æ–°çš„è®­ç»ƒé˜¶æ®µ
        
        Args:
            stage_name: é˜¶æ®µåç§°
            stage_config: é˜¶æ®µé…ç½®å‚æ•°
        """
        self.current_stage += 1
        print(f"ğŸ”„ å¼€å§‹è®­ç»ƒé˜¶æ®µ {self.current_stage}: {stage_name}")
        self.diagnostic_results[f'stage_{self.current_stage}'] = {
            'name': stage_name,
            'config': stage_config,
            'start_epoch': len(self.metrics_history['epoch']),
            'metrics': defaultdict(list)
        }
    
    def end_training_stage(self):
        """
        ç»“æŸå½“å‰è®­ç»ƒé˜¶æ®µå¹¶è®°å½•ç»“æœ
        """
        stage_key = f'stage_{self.current_stage}'
        if stage_key in self.diagnostic_results:
            self.diagnostic_results[stage_key]['end_epoch'] = len(self.metrics_history['epoch']) - 1
            print(f"âœ… å®Œæˆè®­ç»ƒé˜¶æ®µ {self.current_stage}: {self.diagnostic_results[stage_key]['name']}")
    
    def analyze_convergence(self, patience=10, min_improvement=1e-4):
        """
        åˆ†ææ¨¡å‹æ”¶æ•›æƒ…å†µ
        
        Args:
            patience: æ—©åœè€å¿ƒå€¼
            min_improvement: æœ€å°æ”¹è¿›é˜ˆå€¼
            
        Returns:
            dict: æ”¶æ•›åˆ†æç»“æœ
        """
        if len(self.metrics_history['val_loss']) < patience:
            return {'status': 'incomplete', 'message': 'è®­ç»ƒè½®æ¬¡ä¸è¶³ï¼Œæ— æ³•åˆ†ææ”¶æ•›æƒ…å†µ'}
        
        val_losses = self.metrics_history['val_loss']
        best_loss = min(val_losses)
        best_epoch = val_losses.index(best_loss)
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æ‹Ÿåˆ
        recent_epochs = len(val_losses) - 1
        recent_loss = val_losses[-1]
        
        # æ£€æŸ¥æœ€åpatienceè½®æ˜¯å¦æœ‰æ”¹è¿›
        has_recent_improvement = False
        for i in range(1, patience + 1):
            if recent_epochs - i >= 0 and val_losses[recent_epochs - i] > recent_loss + min_improvement:
                has_recent_improvement = True
                break
        
        # è®¡ç®—æ”¶æ•›ç‡
        if len(val_losses) > 10:
            initial_loss = np.mean(val_losses[:10])
            convergence_rate = (initial_loss - best_loss) / initial_loss
        else:
            convergence_rate = None
        
        result = {
            'status': 'converged' if not has_recent_improvement else 'converging',
            'best_epoch': best_epoch,
            'best_loss': best_loss,
            'final_loss': recent_loss,
            'convergence_rate': convergence_rate,
            'overfitting': recent_loss > best_loss * 1.1,
            'suggestion': self._generate_convergence_suggestion(has_recent_improvement, recent_loss, best_loss, convergence_rate)
        }
        
        self.diagnostic_results['convergence_analysis'] = result
        return result
    
    def _generate_convergence_suggestion(self, has_improvement, recent_loss, best_loss, convergence_rate):
        """ç”Ÿæˆæ”¶æ•›å»ºè®®"""
        if not has_improvement:
            if recent_loss < 0.01:
                return "æ¨¡å‹å·²å¾ˆå¥½æ”¶æ•›ï¼Œæ€§èƒ½ä¼˜ç§€"
            elif convergence_rate is not None and convergence_rate < 0.5:
                return "æ”¶æ•›ç‡è¾ƒä½ï¼Œå»ºè®®å¢åŠ è®­ç»ƒè½®æ¬¡æˆ–è°ƒæ•´å­¦ä¹ ç‡"
            else:
                return "æ¨¡å‹å·²æ”¶æ•›ï¼Œå¯ä»¥è€ƒè™‘æ—©åœæˆ–è°ƒæ•´è¶…å‚æ•°ä»¥è¿›ä¸€æ­¥æå‡"
        else:
            return "æ¨¡å‹ä»åœ¨æ”¶æ•›ä¸­ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒ"
    
    def analyze_model_bias_variance(self, model, X_train, y_train, X_val, y_val):
        """
        åˆ†ææ¨¡å‹çš„åå·®-æ–¹å·®æƒè¡¡
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_train: è®­ç»ƒæ•°æ®ç‰¹å¾
            y_train: è®­ç»ƒæ•°æ®æ ‡ç­¾
            X_val: éªŒè¯æ•°æ®ç‰¹å¾
            y_val: éªŒè¯æ•°æ®æ ‡ç­¾
            
        Returns:
            dict: åå·®-æ–¹å·®åˆ†æç»“æœ
        """
        model.eval()
        
        with torch.no_grad():
            # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            X_train = torch.tensor(X_train, dtype=torch.float32).to(self.device)
            y_train = torch.tensor(y_train, dtype=torch.float32).to(self.device)
            X_val = torch.tensor(X_val, dtype=torch.float32).to(self.device)
            y_val = torch.tensor(y_val, dtype=torch.float32).to(self.device)
            
            # è·å–é¢„æµ‹ç»“æœ
            train_pred = model(X_train)
            val_pred = model(X_val)
            
            # è®¡ç®—å„ç§è¯¯å·®æŒ‡æ ‡
            train_mse = mean_squared_error(y_train.cpu().numpy(), train_pred.cpu().numpy())
            val_mse = mean_squared_error(y_val.cpu().numpy(), val_pred.cpu().numpy())
            train_mae = mean_absolute_error(y_train.cpu().numpy(), train_pred.cpu().numpy())
            val_mae = mean_absolute_error(y_val.cpu().numpy(), val_pred.cpu().numpy())
            train_r2 = r2_score(y_train.cpu().numpy(), train_pred.cpu().numpy())
            val_r2 = r2_score(y_val.cpu().numpy(), val_pred.cpu().numpy())
        
        # è®¡ç®—è¿‡æ‹Ÿåˆåº¦ï¼ˆè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®çš„å·®å¼‚ï¼‰
        overfit_ratio = val_mse / train_mse if train_mse > 0 else float('inf')
        
        # åˆ†æç»“æœ
        if train_mse > 0.1 and overfit_ratio < 1.5:
            status = "é«˜åå·®"  # æ¬ æ‹Ÿåˆ
            suggestion = "æ¨¡å‹å¯èƒ½æ¬ æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æ¨¡å‹å¤æ‚åº¦æˆ–å‡å°‘æ­£åˆ™åŒ–"
        elif overfit_ratio > 2.0:
            status = "é«˜æ–¹å·®"  # è¿‡æ‹Ÿåˆ
            suggestion = "æ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–ã€ä½¿ç”¨æ—©åœæˆ–å¢åŠ æ•°æ®å¢å¼º"
        else:
            status = "è‰¯å¥½å¹³è¡¡"  # å¹³è¡¡çŠ¶æ€
            suggestion = "æ¨¡å‹åå·®-æ–¹å·®å¹³è¡¡è‰¯å¥½"
        
        result = {
            'status': status,
            'train_metrics': {'mse': train_mse, 'mae': train_mae, 'r2': train_r2},
            'val_metrics': {'mse': val_mse, 'mae': val_mae, 'r2': val_r2},
            'overfit_ratio': overfit_ratio,
            'suggestion': suggestion
        }
        
        self.diagnostic_results['bias_variance_analysis'] = result
        return result
    
    def analyze_physics_integration(self):
        """
        åˆ†æç‰©ç†çº¦æŸé›†æˆæ•ˆæœ
        
        Returns:
            dict: ç‰©ç†çº¦æŸåˆ†æç»“æœ
        """
        if 'physics_loss' not in self.metrics_history or 'data_loss' not in self.metrics_history:
            return {'status': 'incomplete', 'message': 'ç¼ºå°‘ç‰©ç†æŸå¤±æˆ–æ•°æ®æŸå¤±è®°å½•'}
        
        physics_losses = np.array(self.metrics_history['physics_loss'])
        data_losses = np.array(self.metrics_history['data_loss'])
        
        # è®¡ç®—ç‰©ç†çº¦æŸå’Œæ•°æ®çº¦æŸçš„ç›¸å¯¹é‡è¦æ€§å˜åŒ–
        if len(physics_losses) > 0 and len(data_losses) > 0:
            initial_physics_weight = physics_losses[0] / (data_losses[0] + 1e-10)
            final_physics_weight = physics_losses[-1] / (data_losses[-1] + 1e-10)
            physics_weight_change = (final_physics_weight - initial_physics_weight) / (initial_physics_weight + 1e-10)
            
            # è®¡ç®—ç‰©ç†æŸå¤±çš„ä¸‹é™ç‡
            physics_reduction = (physics_losses[0] - physics_losses[-1]) / (physics_losses[0] + 1e-10)
            data_reduction = (data_losses[0] - data_losses[-1]) / (data_losses[0] + 1e-10)
            
            # åˆ†æç‰©ç†çº¦æŸçš„æœ‰æ•ˆæ€§
            if physics_reduction > 0.5 and data_reduction > 0.3:
                effectiveness = "ä¼˜ç§€"
                suggestion = "ç‰©ç†çº¦æŸæœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½"
            elif physics_reduction > 0.3:
                effectiveness = "è‰¯å¥½"
                suggestion = "ç‰©ç†çº¦æŸå¯¹æ¨¡å‹è®­ç»ƒæœ‰ç§¯æå½±å“"
            else:
                effectiveness = "å¾…æ”¹è¿›"
                suggestion = "ç‰©ç†çº¦æŸæ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®è°ƒæ•´æƒé‡æˆ–æ”¹è¿›ç‰©ç†æ¨¡å‹"
            
            result = {
                'physics_reduction': physics_reduction,
                'data_reduction': data_reduction,
                'physics_weight_change': physics_weight_change,
                'effectiveness': effectiveness,
                'suggestion': suggestion
            }
            
            self.diagnostic_results['physics_integration_analysis'] = result
            return result
        
        return {'status': 'incomplete', 'message': 'ç‰©ç†æŸå¤±æˆ–æ•°æ®æŸå¤±è®°å½•ä¸è¶³'}
    
    def analyze_gradient_flow(self, model):
        """
        åˆ†ææ¢¯åº¦æµåŠ¨æƒ…å†µï¼Œæ£€æµ‹æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸é—®é¢˜
        
        Args:
            model: è®­ç»ƒä¸­çš„æ¨¡å‹
            
        Returns:
            dict: æ¢¯åº¦æµåŠ¨åˆ†æç»“æœ
        """
        gradient_stats = {}
        gradient_norms = []
        
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                gradient_norms.append(grad_norm)
                
                # æ£€æŸ¥æ¢¯åº¦å¼‚å¸¸
                if grad_norm < 1e-6:
                    status = "æ¢¯åº¦æ¶ˆå¤±"
                elif grad_norm > 1e3:
                    status = "æ¢¯åº¦çˆ†ç‚¸"
                else:
                    status = "æ­£å¸¸"
                
                gradient_stats[name] = {
                    'norm': grad_norm,
                    'status': status,
                    'parameter_norm': param.norm().item()
                }
        
        # è®¡ç®—æ•´ä½“æ¢¯åº¦ç»Ÿè®¡
        if gradient_norms:
            avg_grad_norm = np.mean(gradient_norms)
            std_grad_norm = np.std(gradient_norms)
            
            # åˆ†ææ¢¯åº¦å¥åº·çŠ¶å†µ
            if avg_grad_norm < 1e-6:
                overall_status = "ä¸¥é‡æ¢¯åº¦æ¶ˆå¤±"
                suggestion = "æ¢¯åº¦æ¶ˆå¤±ä¸¥é‡ï¼Œå»ºè®®ä½¿ç”¨æ®‹å·®è¿æ¥ã€BatchNormæˆ–è°ƒæ•´æ¿€æ´»å‡½æ•°"
            elif avg_grad_norm > 1e3:
                overall_status = "ä¸¥é‡æ¢¯åº¦çˆ†ç‚¸"
                suggestion = "æ¢¯åº¦çˆ†ç‚¸ä¸¥é‡ï¼Œå»ºè®®ä½¿ç”¨æ¢¯åº¦è£å‰ªã€æƒé‡åˆå§‹åŒ–æˆ–å­¦ä¹ ç‡è°ƒæ•´"
            elif std_grad_norm > avg_grad_norm * 5:
                overall_status = "æ¢¯åº¦ä¸å¹³è¡¡"
                suggestion = "ä¸åŒå±‚æ¢¯åº¦å·®å¼‚å¤§ï¼Œå»ºè®®ä½¿ç”¨æ¢¯åº¦å‡è¡¡æŠ€æœ¯"
            else:
                overall_status = "å¥åº·"
                suggestion = "æ¢¯åº¦æµåŠ¨è‰¯å¥½"
            
            result = {
                'overall_status': overall_status,
                'avg_gradient_norm': avg_grad_norm,
                'std_gradient_norm': std_grad_norm,
                'gradient_stats': gradient_stats,
                'suggestion': suggestion
            }
        else:
            result = {'status': 'incomplete', 'message': 'æ²¡æœ‰å¯ç”¨çš„æ¢¯åº¦ä¿¡æ¯ï¼Œç¡®ä¿åœ¨åå‘ä¼ æ’­åè°ƒç”¨æ­¤å‡½æ•°'}
        
        self.diagnostic_results['gradient_analysis'] = result
        return result
    
    def plot_training_curves(self, save_fig=True):
        """
        ç»˜åˆ¶è®­ç»ƒæ›²çº¿å›¾
        
        Args:
            save_fig: æ˜¯å¦ä¿å­˜å›¾è¡¨
            
        Returns:
            str: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # ç¡®ä¿epochæ•°ç»„å­˜åœ¨
        if 'epoch' not in self.metrics_history or len(self.metrics_history['epoch']) == 0:
            print("âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®æ¥ç»˜åˆ¶æ›²çº¿å›¾")
            plt.close()
            return None
        
        epoch_array = np.array(self.metrics_history['epoch'])
        
        # æŸå¤±æ›²çº¿
        if 'train_loss' in self.metrics_history and len(self.metrics_history['train_loss']) == len(epoch_array):
            axes[0, 0].plot(epoch_array, self.metrics_history['train_loss'], label='è®­ç»ƒæŸå¤±')
        if 'val_loss' in self.metrics_history and len(self.metrics_history['val_loss']) == len(epoch_array):
            axes[0, 0].plot(epoch_array, self.metrics_history['val_loss'], label='éªŒè¯æŸå¤±')
        axes[0, 0].set_title('è®­ç»ƒä¸éªŒè¯æŸå¤±')
        axes[0, 0].set_xlabel('è½®æ¬¡')
        axes[0, 0].set_ylabel('æŸå¤±å€¼')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # MAEæ›²çº¿
        if 'train_mae' in self.metrics_history and 'val_mae' in self.metrics_history:
            if len(self.metrics_history['train_mae']) == len(epoch_array):
                axes[0, 1].plot(epoch_array, self.metrics_history['train_mae'], label='è®­ç»ƒMAE')
            if len(self.metrics_history['val_mae']) == len(epoch_array):
                axes[0, 1].plot(epoch_array, self.metrics_history['val_mae'], label='éªŒè¯MAE')
            axes[0, 1].set_title('è®­ç»ƒä¸éªŒè¯MAE')
            axes[0, 1].set_xlabel('è½®æ¬¡')
            axes[0, 1].set_ylabel('MAEå€¼')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        
        # ç‰©ç†ä¸æ•°æ®æŸå¤±
        if 'physics_loss' in self.metrics_history and 'data_loss' in self.metrics_history:
            if len(self.metrics_history['physics_loss']) == len(epoch_array):
                axes[1, 0].plot(epoch_array, self.metrics_history['physics_loss'], label='ç‰©ç†æŸå¤±')
            if len(self.metrics_history['data_loss']) == len(epoch_array):
                axes[1, 0].plot(epoch_array, self.metrics_history['data_loss'], label='æ•°æ®æŸå¤±')
            axes[1, 0].set_title('ç‰©ç†çº¦æŸæŸå¤±ä¸æ•°æ®æŸå¤±')
            axes[1, 0].set_xlabel('è½®æ¬¡')
            axes[1, 0].set_ylabel('æŸå¤±å€¼')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡æ›²çº¿
        if 'learning_rate' in self.metrics_history and len(self.metrics_history['learning_rate']) == len(epoch_array):
            axes[1, 1].plot(epoch_array, self.metrics_history['learning_rate'], label='å­¦ä¹ ç‡')
            axes[1, 1].set_title('å­¦ä¹ ç‡å˜åŒ–')
            axes[1, 1].set_xlabel('è½®æ¬¡')
            axes[1, 1].set_ylabel('å­¦ä¹ ç‡')
            axes[1, 1].set_yscale('log')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_fig:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(self.save_dir, f'training_curves_{timestamp}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å›¾å·²ä¿å­˜: {save_path}")
            plt.close()
            return save_path
        
        return None
    
    def plot_error_distribution(self, model, X_test, y_test, save_fig=True):
        """
        ç»˜åˆ¶é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_test: æµ‹è¯•æ•°æ®ç‰¹å¾
            y_test: æµ‹è¯•æ•°æ®æ ‡ç­¾
            save_fig: æ˜¯å¦ä¿å­˜å›¾è¡¨
            
        Returns:
            str: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
        """
        model.eval()
        
        with torch.no_grad():
            X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(self.device)
            y_pred = model(X_test_tensor).cpu().numpy()
            
        # è®¡ç®—è¯¯å·®
        y_true = y_test
        errors = y_pred.flatten() - y_true.flatten()
        
        # ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒå›¾
        plt.figure(figsize=(10, 6))
        sns.histplot(errors, kde=True, bins=50)
        plt.axvline(x=0, color='r', linestyle='--', label='é›¶è¯¯å·®')
        plt.title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        plt.xlabel('é¢„æµ‹è¯¯å·®')
        plt.ylabel('é¢‘ç‡')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        if save_fig:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(self.save_dir, f'error_distribution_{timestamp}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š è¯¯å·®åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
            plt.close()
            return save_path
        
        return None
    
    def plot_feature_importance(self, model, feature_names=None, top_n=20, save_fig=True):
        """
        ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾ï¼ˆåŸºäºè¾“å…¥å±‚æƒé‡ï¼‰
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            top_n: æ˜¾ç¤ºå‰Nä¸ªé‡è¦ç‰¹å¾
            save_fig: æ˜¯å¦ä¿å­˜å›¾è¡¨
            
        Returns:
            str: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
        """
        # å°è¯•è·å–è¾“å…¥å±‚æƒé‡
        for name, param in model.named_parameters():
            if 'input' in name.lower() and 'weight' in name.lower():
                weights = param.data.abs().cpu().numpy()
                break
        else:
            print("âš ï¸  æ— æ³•æ‰¾åˆ°è¾“å…¥å±‚æƒé‡ï¼Œè·³è¿‡ç‰¹å¾é‡è¦æ€§åˆ†æ")
            return None
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡æƒé‡
        if len(weights.shape) > 1:
            feature_importance = np.mean(weights, axis=0)
        else:
            feature_importance = weights
        
        # è·å–å‰Nä¸ªé‡è¦ç‰¹å¾
        top_indices = np.argsort(feature_importance)[::-1][:top_n]
        top_importance = feature_importance[top_indices]
        
        # ç‰¹å¾åç§°
        if feature_names is None:
            feature_names = [f'ç‰¹å¾_{i}' for i in range(len(feature_importance))]
        top_features = [feature_names[i] for i in top_indices]
        
        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        plt.figure(figsize=(12, 8))
        plt.barh(range(len(top_features)), top_importance, tick_label=top_features)
        plt.gca().invert_yaxis()  # æœ€é‡è¦çš„ç‰¹å¾åœ¨é¡¶éƒ¨
        plt.title(f'å‰{top_n}ä¸ªé‡è¦ç‰¹å¾')
        plt.xlabel('ç‰¹å¾é‡è¦æ€§ï¼ˆæƒé‡ç»å¯¹å€¼ï¼‰')
        plt.grid(True, axis='x', alpha=0.3)
        
        if save_fig:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(self.save_dir, f'feature_importance_{timestamp}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜: {save_path}")
            plt.close()
            return save_path
        
        return None
    
    def generate_performance_report(self):
        """
        ç”Ÿæˆå®Œæ•´çš„æ€§èƒ½æŠ¥å‘Š
        
        Returns:
            dict: å®Œæ•´çš„æ€§èƒ½æŠ¥å‘Š
        """
        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        convergence_result = self.analyze_convergence()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'training_summary': {
                'total_epochs': len(self.metrics_history['epoch']),
                'best_train_loss': min(self.metrics_history['train_loss']),
                'best_val_loss': min(self.metrics_history['val_loss']),
                'final_train_loss': self.metrics_history['train_loss'][-1],
                'final_val_loss': self.metrics_history['val_loss'][-1],
                'training_stages': self.current_stage
            },
            'convergence_analysis': convergence_result,
            'diagnostic_results': self.diagnostic_results,
            'recommendations': self._generate_recommendations()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(self.save_dir, f'performance_report_{timestamp}.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ‰“å°å…³é”®å‘ç°
        self._print_key_findings(report)
        
        return report
    
    def _generate_recommendations(self):
        """
        æ ¹æ®åˆ†æç»“æœç”Ÿæˆå»ºè®®
        
        Returns:
            list: å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        # åŸºäºæ”¶æ•›åˆ†æçš„å»ºè®®
        if 'convergence_analysis' in self.diagnostic_results:
            conv = self.diagnostic_results['convergence_analysis']
            if 'suggestion' in conv:
                recommendations.append(conv['suggestion'])
        
        # åŸºäºåå·®-æ–¹å·®åˆ†æçš„å»ºè®®
        if 'bias_variance_analysis' in self.diagnostic_results:
            bv = self.diagnostic_results['bias_variance_analysis']
            if 'suggestion' in bv:
                recommendations.append(bv['suggestion'])
        
        # åŸºäºç‰©ç†é›†æˆåˆ†æçš„å»ºè®®
        if 'physics_integration_analysis' in self.diagnostic_results:
            pi = self.diagnostic_results['physics_integration_analysis']
            if 'suggestion' in pi:
                recommendations.append(pi['suggestion'])
        
        # åŸºäºæ¢¯åº¦åˆ†æçš„å»ºè®®
        if 'gradient_analysis' in self.diagnostic_results:
            ga = self.diagnostic_results['gradient_analysis']
            if 'suggestion' in ga:
                recommendations.append(ga['suggestion'])
        
        return recommendations
    
    def _print_key_findings(self, report):
        """
        æ‰“å°å…³é”®å‘ç°
        
        Args:
            report: æ€§èƒ½æŠ¥å‘Š
        """
        print("\nğŸ” æ¨¡å‹æ€§èƒ½å…³é”®å‘ç°:")
        print(f"ğŸ“Š æ€»è®­ç»ƒè½®æ¬¡: {report['training_summary']['total_epochs']}")
        print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {report['training_summary']['best_val_loss']:.6f}")
        print(f"ğŸ“ˆ æœ€ç»ˆéªŒè¯æŸå¤±: {report['training_summary']['final_val_loss']:.6f}")
        
        # æ”¶æ•›çŠ¶æ€
        if 'convergence_analysis' in report:
            conv = report['convergence_analysis']
            if 'status' in conv:
                status_map = {
                    'converged': 'âœ… å·²æ”¶æ•›',
                    'converging': 'â³ æ”¶æ•›ä¸­',
                    'incomplete': 'â“ æ— æ³•åˆ¤æ–­'
                }
                print(f"ğŸ“‰ æ”¶æ•›çŠ¶æ€: {status_map.get(conv['status'], conv['status'])}")
        
        # åå·®-æ–¹å·®çŠ¶æ€
        if 'bias_variance_analysis' in report:
            bv = report['bias_variance_analysis']
            if 'status' in bv:
                print(f"âš–ï¸  åå·®-æ–¹å·®çŠ¶æ€: {bv['status']}")
        
        # ç‰©ç†çº¦æŸæ•ˆæœ
        if 'physics_integration_analysis' in report:
            pi = report['physics_integration_analysis']
            if 'effectiveness' in pi:
                print(f"ğŸ”§ ç‰©ç†çº¦æŸæ•ˆæœ: {pi['effectiveness']}")
        
        # å»ºè®®
        if 'recommendations' in report and report['recommendations']:
            print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"   {i}. {rec}")
    
    def export_diagnostics(self):
        """
        å¯¼å‡ºæ‰€æœ‰è¯Šæ–­ç»“æœå’Œå¯è§†åŒ–å›¾è¡¨
        
        Returns:
            dict: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        export_paths = {}
        
        # ä¿å­˜è®­ç»ƒæ›²çº¿å›¾
        export_paths['training_curves'] = self.plot_training_curves(save_fig=True)
        
        # ç”Ÿæˆå¹¶ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report = self.generate_performance_report()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_paths['performance_report'] = os.path.join(self.save_dir, f'performance_report_{timestamp}.json')
        
        print("\nğŸ“¤ è¯Šæ–­ç»“æœå¯¼å‡ºå®Œæˆ!")
        for key, path in export_paths.items():
            if path:
                print(f"   - {key}: {path}")
        
        return export_paths

# è¾…åŠ©å‡½æ•°
import json

def analyze_checkpoint(checkpoint_path, device='cpu'):
    """
    åˆ†æå·²ä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        dict: æ£€æŸ¥ç‚¹åˆ†æç»“æœ
    """
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # æå–å…³é”®ä¿¡æ¯
        analysis = {
            'checkpoint_path': checkpoint_path,
            'model_architecture': 'OptimizedEWPINN',
            'has_state_dict': 'model_state_dict' in checkpoint,
            'has_normalizer': 'normalizer' in checkpoint,
            'has_config': 'config' in checkpoint,
            'has_history': 'train_history' in checkpoint and 'val_history' in checkpoint,
            'hyperparameter_optimization': 'hyperparameter_optimization_history' in checkpoint
        }
        
        # æå–è®­ç»ƒå†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        if analysis['has_history']:
            analysis['training_epochs'] = len(checkpoint['train_history'])
            analysis['best_train_loss'] = min(checkpoint['train_history'])
            analysis['best_val_loss'] = min(checkpoint['val_history'])
        
        # æå–è¶…å‚æ•°ä¼˜åŒ–ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if analysis['hyperparameter_optimization']:
            analysis['optimization_rounds'] = len(checkpoint['hyperparameter_optimization_history'])
            analysis['best_hyperparameters'] = checkpoint['best_hyperparameters']
        
        print(f"âœ… æ£€æŸ¥ç‚¹åˆ†æå®Œæˆ: {checkpoint_path}")
        return analysis
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ç‚¹åˆ†æå¤±è´¥: {str(e)}")
        return {'error': str(e), 'checkpoint_path': checkpoint_path}

def compare_models(model_paths, device='cpu'):
    """
    æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½
    
    Args:
        model_paths: æ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        dict: æ¨¡å‹æ¯”è¾ƒç»“æœ
    """
    comparisons = []
    
    for path in model_paths:
        try:
            analysis = analyze_checkpoint(path, device)
            comparisons.append({
                'model_path': path,
                'best_val_loss': analysis.get('best_val_loss', float('inf')),
                'training_epochs': analysis.get('training_epochs', 0),
                'has_hyperopt': analysis.get('hyperparameter_optimization', False),
                'optimization_rounds': analysis.get('optimization_rounds', 0)
            })
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ†ææ¨¡å‹: {path}, é”™è¯¯: {str(e)}")
    
    # æŒ‰æœ€ä½³éªŒè¯æŸå¤±æ’åº
    comparisons.sort(key=lambda x: x['best_val_loss'])
    
    print("\nğŸ† æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:")
    for i, model in enumerate(comparisons, 1):
        print(f"   {i}. æ¨¡å‹: {os.path.basename(model['model_path'])}")
        print(f"      æœ€ä½³éªŒè¯æŸå¤±: {model['best_val_loss']:.6f}")
        print(f"      è®­ç»ƒè½®æ¬¡: {model['training_epochs']}")
        print(f"      è¶…å‚æ•°ä¼˜åŒ–: {'âœ… æ˜¯' if model['has_hyperopt'] else 'âŒ å¦'} ({model['optimization_rounds']}è½®)")
    
    return comparisons