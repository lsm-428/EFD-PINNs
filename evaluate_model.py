#!/usr/bin/env python3
"""
æ¨¡å‹è¯„ä¼°è„šæœ¬
å¯¹è®­ç»ƒå¥½çš„EFD-PINNsæ¨¡å‹è¿›è¡Œå…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬:
1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
2. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
3. åˆ†æåŠ¨æ€å“åº”ç‰¹æ€§ï¼ˆè¶…è°ƒã€å“åº”æ—¶é—´ç­‰ï¼‰
4. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šå’Œå¯è§†åŒ–
"""

import os
import json
import numpy as np
import torch
import matplotlib.pyplot as plt
import torch.nn as nn
from datetime import datetime
import argparse

# å¯¼å…¥æ¨¡å‹ç›¸å…³æ¨¡å—
from efd_pinns_train import OptimizedEWPINN


def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        config = json.load(f)
    return config


def load_model(model_path, config):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    from efd_pinns_train import DataNormalizer
    
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åŠ è½½checkpointè·å–å®é™…æ¨¡å‹é…ç½®
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # ä»checkpointä¸­è·å–ä¿å­˜çš„é…ç½®
    saved_config = checkpoint.get('config', config)
    model_config = saved_config.get('model', config.get('model', {}))
    
    input_dim = model_config.get('input_dim', 62)
    output_dim = model_config.get('output_dim', 24)
    
    # ä»state_dictæ¨æ–­hidden_dims
    state_dict = checkpoint.get('model_state_dict', checkpoint)
    
    # åˆ†æç½‘ç»œç»“æ„ - æ‰¾å‡ºæ‰€æœ‰Linearå±‚çš„è¾“å‡ºç»´åº¦
    linear_layers = []
    for key, value in sorted(state_dict.items()):
        if 'main_layers' in key and '.weight' in key and 'running' not in key:
            if len(value.shape) == 2:  # Linearå±‚
                linear_layers.append((key, value.shape))
    
    # æå–hidden_dims (é™¤äº†æœ€åä¸€å±‚è¾“å‡ºå±‚)
    hidden_dims = []
    for key, shape in linear_layers[:-1]:  # æ’é™¤æœ€åçš„è¾“å‡ºå±‚
        hidden_dims.append(shape[0])
    
    if not hidden_dims:
        hidden_dims = [128, 128, 128]  # é»˜è®¤å€¼
    
    print(f"   æ¨æ–­çš„hidden_dims: {hidden_dims}")
    print(f"   input_dim: {input_dim}, output_dim: {output_dim}")
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = OptimizedEWPINN(
        input_dim=input_dim,
        hidden_dims=hidden_dims,
        output_dim=output_dim,
        activation=model_config.get('activation', 'gelu'),
        config=saved_config
    )
    
    # åŠ è½½æƒé‡
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"   Epoch: {checkpoint.get('epoch', 'N/A')}")
        print(f"   Loss: {checkpoint.get('loss', 'N/A'):.4f}" if checkpoint.get('loss') else "")
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    model.to(device)
    
    # åŠ è½½è¾“å‡ºå½’ä¸€åŒ–å™¨
    output_normalizer = None
    if 'output_normalizer' in checkpoint and checkpoint['output_normalizer'] is not None:
        output_normalizer = DataNormalizer(method="standard")
        output_normalizer.load_state_dict(checkpoint['output_normalizer'])
        print(f"   âœ… å·²åŠ è½½è¾“å‡ºå½’ä¸€åŒ–å™¨")
    else:
        print(f"   âš ï¸ æœªæ‰¾åˆ°è¾“å‡ºå½’ä¸€åŒ–å™¨")
    
    return model, device, output_normalizer, saved_config


def generate_test_data(config, num_samples=200):
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    print(f"ğŸ”§ ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼Œæ ·æœ¬æ•°: {num_samples}")
    
    # å¯¼å…¥æ•°æ®ç”Ÿæˆå‡½æ•°
    from efd_pinns_train import generate_dynamic_ewod_data
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ä¸´æ—¶ä¿®æ”¹æ ·æœ¬æ•°
    config_copy = config.copy()
    if 'data' not in config_copy:
        config_copy['data'] = {}
    config_copy['data']['num_samples'] = num_samples
    
    # ç”Ÿæˆæ•°æ® - è¿”å›: X_train, Y_train, X_val, Y_val, X_test, Y_test, physics_points, normalizers
    result = generate_dynamic_ewod_data(config_copy, device)
    
    # è§£åŒ…ç»“æœ
    X_train, Y_train, X_val, Y_val, X_test, Y_test, physics_points, normalizers = result
    
    # è½¬æ¢ä¸ºnumpy
    X = X_test.cpu().numpy() if torch.is_tensor(X_test) else X_test
    y = Y_test.cpu().numpy() if torch.is_tensor(Y_test) else Y_test
    
    return X, y, None


def evaluate_predictions(model, X, y, device):
    """è¯„ä¼°æ¨¡å‹é¢„æµ‹æ€§èƒ½"""
    print("ğŸ“Š è¯„ä¼°æ¨¡å‹é¢„æµ‹...")
    
    model.eval()
    X_tensor = torch.FloatTensor(X).to(device)
    y_tensor = torch.FloatTensor(y).to(device)
    
    with torch.no_grad():
        outputs = model(X_tensor)
        
        # å¤„ç†è¾“å‡ºæ ¼å¼
        if isinstance(outputs, dict):
            predictions = outputs.get('main_predictions', outputs.get('predictions', None))
            if predictions is None:
                predictions = list(outputs.values())[0]
        else:
            predictions = outputs
    
    predictions = predictions.cpu().numpy()
    targets = y
    
    # è®¡ç®—æŒ‡æ ‡
    mse = np.mean((predictions - targets) ** 2)
    mae = np.mean(np.abs(predictions - targets))
    rmse = np.sqrt(mse)
    
    # è®¡ç®—æ¯ä¸ªè¾“å‡ºçš„RÂ²
    r2_scores = []
    for i in range(targets.shape[1]):
        ss_res = np.sum((targets[:, i] - predictions[:, i]) ** 2)
        ss_tot = np.sum((targets[:, i] - np.mean(targets[:, i])) ** 2)
        r2 = 1 - (ss_res / ss_tot) if ss_tot > 1e-10 else 0
        r2_scores.append(r2)
    
    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2_scores': r2_scores,
        'avg_r2': np.mean(r2_scores),
        'predictions': predictions,
        'targets': targets
    }


def analyze_dynamic_response(model, config, device, output_normalizer=None):
    """åˆ†æåŠ¨æ€å“åº”ç‰¹æ€§"""
    print("âš¡ åˆ†æåŠ¨æ€å“åº”...")
    
    # ç”Ÿæˆé˜¶è·ƒå“åº”æµ‹è¯•æ•°æ®
    num_time_steps = 100
    T_total = 0.02
    time = np.linspace(0, T_total, num_time_steps)  # 0-20ms
    
    # è·å–ææ–™å’Œå‡ ä½•å‚æ•°
    materials = config.get('materials', {})
    geometry = config.get('geometry', {})
    data_config = config.get('data', {})
    
    epsilon_r = materials.get('epsilon_r', 4.0)
    gamma = materials.get('gamma', 0.072)
    d = materials.get('dielectric_thickness', 4e-7)
    theta0 = materials.get('theta0', 110.0)
    
    Lx = geometry.get('Lx', 184e-6)
    Ly = geometry.get('Ly', 184e-6)
    Lz = geometry.get('Lz', 20.855e-6)
    
    # ä»é…ç½®è¯»å–ç”µå‹èŒƒå›´
    voltage_range = data_config.get('voltage_range', [0, 30])
    V_step = voltage_range[1] if isinstance(voltage_range, list) else 30
    
    results = {
        'time': time,
        'voltage': V_step,
        'contact_angles': [],
        'response_metrics': {}
    }
    
    model.eval()
    contact_angles = []
    
    for t_current in time:
        # æ„å»ºè¾“å…¥ç‰¹å¾ (62ç»´) - ä¸è®­ç»ƒæ•°æ®ç”Ÿæˆä¸€è‡´
        features = np.zeros(62, dtype=np.float32)
        
        # å½’ä¸€åŒ–çš„ç©ºé—´åæ ‡
        features[0] = 0.5  # xå½’ä¸€åŒ–
        features[1] = 0.5  # yå½’ä¸€åŒ–
        features[2] = 0.5  # zå½’ä¸€åŒ–
        features[3] = t_current / T_total  # tå½’ä¸€åŒ–
        features[4] = np.sin(2 * np.pi * t_current / T_total)
        features[5] = V_step / 30.0  # Vå½’ä¸€åŒ–
        features[6] = 0.5  # åˆ°è¾¹ç•Œè·ç¦»
        features[7] = 0.0  # åˆ°ä¸­å¿ƒè·ç¦»
        
        X = torch.FloatTensor(features).unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(X)
            if isinstance(outputs, dict):
                pred = outputs.get('main_predictions', list(outputs.values())[0])
            else:
                pred = outputs
            
            # åå½’ä¸€åŒ–è¾“å‡º
            if output_normalizer is not None:
                pred_np = pred.cpu().numpy()
                pred_denorm = output_normalizer.inverse_transform(pred_np)
                # æ¥è§¦è§’åœ¨ç´¢å¼•10 (å¼§åº¦)
                theta_rad = pred_denorm[0, 10]
            else:
                # å¦‚æœæ²¡æœ‰å½’ä¸€åŒ–å™¨ï¼Œå‡è®¾è¾“å‡ºå·²ç»æ˜¯ç‰©ç†å€¼
                theta_rad = pred[0, 10].item()
            
            # è½¬æ¢ä¸ºåº¦
            theta_deg = np.degrees(theta_rad)
            theta_deg = np.clip(theta_deg, 50, 130)  # ç‰©ç†çº¦æŸ
            contact_angles.append(theta_deg)
    
    contact_angles = np.array(contact_angles)
    results['contact_angles'] = contact_angles
    
    # è®¡ç®—å“åº”æŒ‡æ ‡
    theta_initial = contact_angles[0]
    theta_final = contact_angles[-1]
    theta_change = theta_final - theta_initial
    
    if abs(theta_change) > 1e-6:
        # å½’ä¸€åŒ–å“åº”
        normalized = (contact_angles - theta_initial) / theta_change
        
        # å“åº”æ—¶é—´ t90 (è¾¾åˆ°90%å˜åŒ–)
        t90_idx = np.where(np.abs(normalized) >= 0.9)[0]
        t90 = time[t90_idx[0]] * 1000 if len(t90_idx) > 0 else time[-1] * 1000
        
        # è¶…è°ƒ
        if theta_change > 0:
            overshoot = (np.max(contact_angles) - theta_final) / abs(theta_change) * 100
        else:
            overshoot = (theta_final - np.min(contact_angles)) / abs(theta_change) * 100
        overshoot = max(0, overshoot)
        
        # ç¨³å®šæ—¶é—´ (è¿›å…¥Â±5%èŒƒå›´)
        settling_idx = np.where(np.abs(normalized - 1.0) <= 0.05)[0]
        if len(settling_idx) > 0:
            # æ‰¾åˆ°æœ€åä¸€æ¬¡ç¦»å¼€Â±5%èŒƒå›´åçš„æ—¶é—´
            for i in range(len(settling_idx) - 1, -1, -1):
                if settling_idx[i] == len(time) - 1 or all(np.abs(normalized[settling_idx[i]:] - 1.0) <= 0.05):
                    settling_time = time[settling_idx[i]] * 1000
                    break
            else:
                settling_time = time[-1] * 1000
        else:
            settling_time = time[-1] * 1000
    else:
        t90 = 0
        overshoot = 0
        settling_time = 0
        normalized = np.zeros_like(contact_angles)
    
    results['response_metrics'] = {
        'theta_initial': float(theta_initial),
        'theta_final': float(theta_final),
        'theta_change': float(theta_change),
        't90_ms': float(t90),
        'overshoot_percent': float(overshoot),
        'settling_time_ms': float(settling_time)
    }
    
    return results


def create_visualizations(eval_results, dynamic_results, output_dir):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    print("ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. é¢„æµ‹ vs çœŸå®å€¼
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    predictions = eval_results['predictions']
    targets = eval_results['targets']
    
    # é€‰æ‹©å…³é”®è¾“å‡ºç»´åº¦
    key_dims = [0, 6, 12, 18]  # u, theta, å…¶ä»–
    dim_names = ['é€Ÿåº¦u', 'æ¥è§¦è§’Î¸', 'å‹åŠ›p', 'ç•Œé¢ä½ç½®']
    
    for i, (dim, name) in enumerate(zip(key_dims, dim_names)):
        if dim < predictions.shape[1]:
            ax = axes[i // 2, i % 2]
            ax.scatter(targets[:, dim], predictions[:, dim], alpha=0.5, s=10)
            
            # å¯¹è§’çº¿
            lims = [min(targets[:, dim].min(), predictions[:, dim].min()),
                    max(targets[:, dim].max(), predictions[:, dim].max())]
            ax.plot(lims, lims, 'r--', label='ç†æƒ³')
            
            ax.set_xlabel('çœŸå®å€¼')
            ax.set_ylabel('é¢„æµ‹å€¼')
            ax.set_title(f'{name} (RÂ²={eval_results["r2_scores"][dim]:.3f})')
            ax.grid(True, alpha=0.3)
            ax.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'prediction_vs_true.png'), dpi=150)
    plt.close()
    
    # 2. åŠ¨æ€å“åº”æ›²çº¿
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    time_ms = dynamic_results['time'] * 1000
    contact_angles = dynamic_results['contact_angles']
    metrics = dynamic_results['response_metrics']
    
    # æ¥è§¦è§’å“åº”
    ax1 = axes[0]
    ax1.plot(time_ms, contact_angles, 'b-', linewidth=2, label='æ¥è§¦è§’å“åº”')
    ax1.axhline(y=metrics['theta_final'], color='g', linestyle='--', label=f'ç¨³æ€å€¼: {metrics["theta_final"]:.2f}')
    ax1.axvline(x=metrics['t90_ms'], color='r', linestyle=':', label=f't90: {metrics["t90_ms"]:.2f}ms')
    ax1.set_xlabel('æ—¶é—´ (ms)')
    ax1.set_ylabel('æ¥è§¦è§’')
    ax1.set_title(f'é˜¶è·ƒå“åº” (V={dynamic_results["voltage"]}V)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å“åº”æŒ‡æ ‡æ¡å½¢å›¾
    ax2 = axes[1]
    metrics_names = ['t90 (ms)', 'è¶…è°ƒ (%)', 'ç¨³å®šæ—¶é—´ (ms)']
    metrics_values = [metrics['t90_ms'], metrics['overshoot_percent'], metrics['settling_time_ms']]
    colors = ['blue', 'red' if metrics['overshoot_percent'] > 15 else 'green', 'orange']
    
    bars = ax2.bar(metrics_names, metrics_values, color=colors, alpha=0.7)
    ax2.set_ylabel('å€¼')
    ax2.set_title('åŠ¨æ€å“åº”æŒ‡æ ‡')
    
    # æ·»åŠ ç›®æ ‡çº¿
    ax2.axhline(y=15, color='r', linestyle='--', alpha=0.5, label='è¶…è°ƒç›®æ ‡ (<15%)')
    ax2.legend()
    
    # åœ¨æ¡å½¢ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bar, val in zip(bars, metrics_values):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{val:.2f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'dynamic_response.png'), dpi=150)
    plt.close()
    
    # 3. RÂ²åˆ†æ•°åˆ†å¸ƒ
    plt.figure(figsize=(12, 5))
    r2_scores = eval_results['r2_scores']
    x = np.arange(len(r2_scores))
    colors = ['green' if r2 > 0.8 else 'orange' if r2 > 0.5 else 'red' for r2 in r2_scores]
    
    plt.bar(x, r2_scores, color=colors, alpha=0.7)
    plt.axhline(y=0.8, color='g', linestyle='--', alpha=0.5, label='è‰¯å¥½ (RÂ²>0.8)')
    plt.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='ä¸€èˆ¬ (RÂ²>0.5)')
    plt.xlabel('è¾“å‡ºç»´åº¦')
    plt.ylabel('RÂ²åˆ†æ•°')
    plt.title(f'å„è¾“å‡ºç»´åº¦RÂ²åˆ†æ•° (å¹³å‡: {eval_results["avg_r2"]:.3f})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(output_dir, 'r2_scores.png'), dpi=150)
    plt.close()
    
    print(f"   å¯è§†åŒ–ä¿å­˜åˆ°: {output_dir}")


def generate_report(eval_results, dynamic_results, output_dir):
    """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
    print("ğŸ“‹ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    
    metrics = dynamic_results['response_metrics']
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'prediction_metrics': {
            'mse': float(eval_results['mse']),
            'mae': float(eval_results['mae']),
            'rmse': float(eval_results['rmse']),
            'avg_r2': float(eval_results['avg_r2']),
            'min_r2': float(min(eval_results['r2_scores'])),
            'max_r2': float(max(eval_results['r2_scores']))
        },
        'dynamic_response': {
            'voltage': dynamic_results['voltage'],
            'theta_initial': metrics['theta_initial'],
            'theta_final': metrics['theta_final'],
            'theta_change': metrics['theta_change'],
            't90_ms': metrics['t90_ms'],
            'overshoot_percent': metrics['overshoot_percent'],
            'settling_time_ms': metrics['settling_time_ms']
        },
        'quality_assessment': {
            'prediction_quality': 'good' if eval_results['avg_r2'] > 0.8 else 'fair' if eval_results['avg_r2'] > 0.5 else 'poor',
            'overshoot_target_met': metrics['overshoot_percent'] < 15,
            'response_time_reasonable': 1 < metrics['t90_ms'] < 10
        }
    }
    
    report_path = os.path.join(output_dir, 'evaluation_report.json')
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœæ‘˜è¦")
    print("="*60)
    print(f"\nã€é¢„æµ‹æ€§èƒ½ã€‘")
    print(f"  MSE:  {eval_results['mse']:.6f}")
    print(f"  MAE:  {eval_results['mae']:.6f}")
    print(f"  RMSE: {eval_results['rmse']:.6f}")
    print(f"  å¹³å‡RÂ²: {eval_results['avg_r2']:.4f}")
    
    print(f"\nã€åŠ¨æ€å“åº”ã€‘(V={dynamic_results['voltage']}V é˜¶è·ƒ)")
    print(f"  å“åº”æ—¶é—´ t90: {metrics['t90_ms']:.2f} ms")
    print(f"  è¶…è°ƒé‡: {metrics['overshoot_percent']:.2f}%", end="")
    print(" âœ…" if metrics['overshoot_percent'] < 15 else " âŒ (ç›®æ ‡<15%)")
    print(f"  ç¨³å®šæ—¶é—´: {metrics['settling_time_ms']:.2f} ms")
    print(f"  æ¥è§¦è§’å˜åŒ–: {metrics['theta_initial']:.2f}Â° â†’ {metrics['theta_final']:.2f}Â°")
    
    print("\n" + "="*60)
    
    return report


def main():
    parser = argparse.ArgumentParser(description='è¯„ä¼°EFD-PINNsæ¨¡å‹')
    parser.add_argument('--model', type=str, default=None,
                        help='æ¨¡å‹è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°)')
    parser.add_argument('--config', type=str, default='config_stage2_10k.json',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default=None,
                        help='è¾“å‡ºç›®å½• (é»˜è®¤: æ¨¡å‹ç›®å½•/evaluation)')
    parser.add_argument('--num_samples', type=int, default=200,
                        help='æµ‹è¯•æ ·æœ¬æ•°')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ”¬ EFD-PINNs æ¨¡å‹è¯„ä¼°")
    print("="*60)
    
    # è‡ªåŠ¨æŸ¥æ‰¾æ¨¡å‹
    if args.model is None:
        from pathlib import Path
        output_dirs = sorted(Path('.').glob('outputs_*'), key=lambda p: p.stat().st_mtime, reverse=True)
        for d in output_dirs:
            model_path = d / 'final_model.pth'
            if model_path.exists():
                args.model = str(model_path)
                break
        if args.model is None:
            print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            return
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.output is None:
        model_dir = os.path.dirname(args.model)
        args.output = os.path.join(model_dir, 'evaluation')
    
    # åŠ è½½é…ç½®å’Œæ¨¡å‹
    config = load_config(args.config)
    model, device, output_normalizer, saved_config = load_model(args.model, config)
    
    # ä½¿ç”¨ä¿å­˜çš„é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
    config = saved_config if saved_config else config
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    X_test, y_test, _ = generate_test_data(config, args.num_samples)
    
    # è¯„ä¼°é¢„æµ‹æ€§èƒ½
    eval_results = evaluate_predictions(model, X_test, y_test, device)
    
    # åˆ†æåŠ¨æ€å“åº”
    dynamic_results = analyze_dynamic_response(model, config, device, output_normalizer)
    
    # ç”Ÿæˆå¯è§†åŒ–
    create_visualizations(eval_results, dynamic_results, args.output)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(eval_results, dynamic_results, args.output)
    
    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.output}")


if __name__ == "__main__":
    main()
