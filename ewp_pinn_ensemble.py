import torch
import torch.nn as nn
import numpy as np
import os
import json
import copy
from datetime import datetime
import time
from collections import defaultdict
import matplotlib.pyplot as plt
from typing import List, Dict, Any, Optional, Union, Callable

# å¯¼å…¥ç°æœ‰æ¨¡å‹å’Œå·¥å…·
from ewp_pinn_model import OptimizedEWPINN, extract_predictions
from ewp_pinn_optimized_train import load_model, compare_model_performance

class EWPINNEnsembleModel:
    """
    EWPINNé›†æˆæ¨¡å‹ç±»ï¼Œç”¨äºç®¡ç†å¤šä¸ªEWPINNæ¨¡å‹å¹¶æ‰§è¡Œé›†æˆé¢„æµ‹
    
    æ”¯æŒå¤šç§é›†æˆç­–ç•¥ï¼š
    - ç®€å•å¹³å‡ (Simple Average)
    - åŠ æƒå¹³å‡ (Weighted Average)
    - æŠ•ç¥¨æœºåˆ¶ (Voting)
    - å †å é›†æˆ (Stacking)
    """
    
    def __init__(self, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):
        """
        åˆå§‹åŒ–é›†æˆæ¨¡å‹
        
        Args:
            device: è¿è¡Œè®¾å¤‡
        """
        self.device = device
        self.models = []  # å­˜å‚¨æ¨¡å‹åˆ—è¡¨
        self.model_weights = []  # å­˜å‚¨æ¨¡å‹æƒé‡
        self.normalizers = []  # å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„æ•°æ®æ ‡å‡†åŒ–å™¨
        self.model_metadatas = []  # å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„å…ƒæ•°æ®
        self.ensemble_strategy = 'weighted_average'  # é»˜è®¤ä½¿ç”¨åŠ æƒå¹³å‡ç­–ç•¥
        self.ensemble_info = {
            'version': '1.0',
            'creation_time': datetime.now().isoformat(),
            'models_count': 0,
            'strategy': self.ensemble_strategy
        }
    
    def add_model(self, model_path: str, weight: float = 1.0) -> bool:
        """
        æ·»åŠ å•ä¸ªæ¨¡å‹åˆ°é›†æˆ
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            weight: æ¨¡å‹æƒé‡ï¼ˆç”¨äºåŠ æƒå¹³å‡ï¼‰
            
        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
            # ä½¿ç”¨ç°æœ‰çš„load_modelå‡½æ•°åŠ è½½æ¨¡å‹
            model, normalizer, metadata = load_model(model_path, device=self.device)
            
            if model is not None:
                model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                self.models.append(model)
                self.model_weights.append(weight)
                self.normalizers.append(normalizer)
                self.model_metadatas.append(metadata)
                self.ensemble_info['models_count'] += 1
                
                print(f"âœ… æˆåŠŸæ·»åŠ æ¨¡å‹ #{self.ensemble_info['models_count']}")
                print(f"   æ¨¡å‹ä¿¡æ¯: ç‰ˆæœ¬={metadata.get('model_info', {}).get('version', 'unknown')}")
                print(f"   æ¨¡å‹æƒé‡: {weight}")
                
                return True
            else:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {model_path}")
                return False
        except Exception as e:
            print(f"âŒ æ·»åŠ æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def add_models_from_directory(self, directory: str, pattern: str = "*.pth", 
                                 weight_strategy: str = "uniform") -> int:
        """
        ä»ç›®å½•ä¸­æ‰¹é‡æ·»åŠ æ¨¡å‹
        
        Args:
            directory: åŒ…å«æ¨¡å‹æ–‡ä»¶çš„ç›®å½•
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            weight_strategy: æƒé‡ç­–ç•¥ ('uniform', 'performance_based', 'custom')
            
        Returns:
            int: æˆåŠŸæ·»åŠ çš„æ¨¡å‹æ•°é‡
        """
        import glob
        model_paths = glob.glob(os.path.join(directory, pattern))
        added_count = 0
        
        print(f"ğŸ” å‘ç° {len(model_paths)} ä¸ªæ½œåœ¨æ¨¡å‹æ–‡ä»¶")
        
        for i, model_path in enumerate(model_paths):
            print(f"\n[{i+1}/{len(model_paths)}] å¤„ç†: {model_path}")
            
            # æ ¹æ®ç­–ç•¥ç¡®å®šæƒé‡
            if weight_strategy == "uniform":
                weight = 1.0
            else:
                # æš‚æ—¶é»˜è®¤æƒé‡
                weight = 1.0
            
            if self.add_model(model_path, weight):
                added_count += 1
        
        print(f"\nâœ… æ‰¹é‡æ·»åŠ å®Œæˆ: æˆåŠŸæ·»åŠ  {added_count}/{len(model_paths)} ä¸ªæ¨¡å‹")
        
        # å¦‚æœæ˜¯å‡åŒ€æƒé‡ï¼Œå½’ä¸€åŒ–
        if weight_strategy == "uniform" and added_count > 0:
            total_weight = sum(self.model_weights[-added_count:])
            for i in range(len(self.model_weights) - added_count, len(self.model_weights)):
                self.model_weights[i] = self.model_weights[i] / total_weight
            
            print(f"ğŸ”„ å·²å½’ä¸€åŒ–æ¨¡å‹æƒé‡")
        
        return added_count
    
    def set_ensemble_strategy(self, strategy: str) -> None:
        """
        è®¾ç½®é›†æˆç­–ç•¥
        
        Args:
            strategy: é›†æˆç­–ç•¥ï¼Œå¯é€‰å€¼: 'simple_average', 'weighted_average', 'voting'
        """
        valid_strategies = ['simple_average', 'weighted_average', 'voting']
        if strategy not in valid_strategies:
            raise ValueError(f"æ— æ•ˆçš„é›†æˆç­–ç•¥: {strategy}ã€‚æœ‰æ•ˆé€‰é¡¹: {valid_strategies}")
        
        self.ensemble_strategy = strategy
        self.ensemble_info['strategy'] = strategy
        print(f"âœ… å·²è®¾ç½®é›†æˆç­–ç•¥: {strategy}")
    
    def set_model_weights(self, weights: List[float]) -> bool:
        """
        è®¾ç½®æ¨¡å‹æƒé‡ï¼ˆç”¨äºåŠ æƒå¹³å‡ï¼‰
        
        Args:
            weights: æƒé‡åˆ—è¡¨ï¼Œé•¿åº¦å¿…é¡»ä¸æ¨¡å‹æ•°é‡ä¸€è‡´
            
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if len(weights) != len(self.models):
            print(f"âŒ æƒé‡æ•°é‡ ({len(weights)}) ä¸æ¨¡å‹æ•°é‡ ({len(self.models)}) ä¸åŒ¹é…")
            return False
        
        # éªŒè¯æƒé‡æ˜¯å¦ä¸ºæ­£æ•°
        if any(w <= 0 for w in weights):
            print("âŒ æƒé‡å¿…é¡»ä¸ºæ­£æ•°")
            return False
        
        self.model_weights = copy.copy(weights)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(weights)
        self.model_weights = [w / total_weight for w in self.model_weights]
        
        print(f"âœ… å·²è®¾ç½®å¹¶å½’ä¸€åŒ–æ¨¡å‹æƒé‡: {self.model_weights}")
        return True
    
    def predict(self, inputs: torch.Tensor, use_normalization: bool = True) -> torch.Tensor:
        """
        ä½¿ç”¨é›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            inputs: è¾“å…¥æ•°æ®å¼ é‡
            use_normalization: æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–å™¨
            
        Returns:
            torch.Tensor: é›†æˆé¢„æµ‹ç»“æœ
        """
        if not self.models:
            raise ValueError("é›†æˆæ¨¡å‹ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ æ¨¡å‹")
        
        # ç¡®ä¿è¾“å…¥åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        inputs = inputs.to(self.device)
        
        with torch.no_grad():
            # åº”ç”¨æ ‡å‡†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
            normalized_inputs = []
            for i, normalizer in enumerate(self.normalizers):
                if use_normalization and normalizer is not None:
                    normalized_inputs.append(normalizer.transform_features(inputs.clone()))
                else:
                    normalized_inputs.append(inputs.clone())
            
            # è·å–æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ï¼ˆç¡®ä¿æå–ä¸ºå¼ é‡ï¼‰
            all_predictions = []
            for i, (model, norm_input) in enumerate(zip(self.models, normalized_inputs)):
                raw_pred = model(norm_input)
                try:
                    pred = extract_predictions(raw_pred)
                except Exception:
                    # å…¼å®¹ fallbackï¼šå°è¯•å°† numpy/list è½¬ä¸º tensor
                    if isinstance(raw_pred, (list, tuple, np.ndarray)):
                        pred = torch.tensor(raw_pred, device=self.device)
                    else:
                        pred = torch.as_tensor(raw_pred).to(self.device)

                all_predictions.append(pred)
            
            # æ ¹æ®ç­–ç•¥è¿›è¡Œé›†æˆ
            if self.ensemble_strategy == 'simple_average':
                # ç®€å•å¹³å‡
                ensemble_pred = torch.stack(all_predictions).mean(dim=0)
            
            elif self.ensemble_strategy == 'weighted_average':
                # åŠ æƒå¹³å‡
                weighted_preds = [pred * weight for pred, weight in zip(all_predictions, self.model_weights)]
                ensemble_pred = torch.stack(weighted_preds).sum(dim=0)
            
            elif self.ensemble_strategy == 'voting':
                # æŠ•ç¥¨æœºåˆ¶ï¼ˆå¯¹äºå›å½’é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸­ä½æ•°ï¼‰
                ensemble_pred = torch.stack(all_predictions).median(dim=0)[0]
            
            return ensemble_pred
    
    def evaluate(self, test_data: torch.Tensor, test_labels: torch.Tensor, 
                use_normalization: bool = True) -> Dict[str, float]:
        """
        è¯„ä¼°é›†æˆæ¨¡å‹æ€§èƒ½
        
        Args:
            test_data: æµ‹è¯•æ•°æ®
            test_labels: æµ‹è¯•æ ‡ç­¾
            use_normalization: æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–å™¨
            
        Returns:
            Dict: è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        test_data = test_data.to(self.device)
        test_labels = test_labels.to(self.device)
        
        # åº”ç”¨æ ‡ç­¾æ ‡å‡†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if use_normalization and self.normalizers[0] is not None:
            original_test_labels = test_labels.clone()  # ä¿å­˜åŸå§‹æ ‡ç­¾ç”¨äºè¯„ä¼°
            normalized_test_labels = self.normalizers[0].transform_labels(test_labels)
        else:
            original_test_labels = test_labels
            normalized_test_labels = test_labels
        
        # è·å–é¢„æµ‹ç»“æœ
        predictions = self.predict(test_data, use_normalization)
        
        # åå‘æ ‡å‡†åŒ–é¢„æµ‹ç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        if use_normalization and self.normalizers[0] is not None:
            predictions = self.normalizers[0].inverse_transform_labels(predictions)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = {
            'ensemble_mse': nn.MSELoss()(predictions, original_test_labels).item(),
            'ensemble_mae': nn.L1Loss()(predictions, original_test_labels).item(),
            'ensemble_rmse': torch.sqrt(nn.MSELoss()(predictions, original_test_labels)).item()
        }
        
        # è®¡ç®—æ¯ä¸ªå•ç‹¬æ¨¡å‹çš„æ€§èƒ½
        individual_metrics = []
        for i, (model, normalizer) in enumerate(zip(self.models, self.normalizers)):
            with torch.no_grad():
                # å¯¹æ¯ä¸ªæ¨¡å‹åº”ç”¨å…¶ç‰¹å®šçš„æ ‡å‡†åŒ–
                model_inputs = normalizer.transform_features(test_data.clone()) if use_normalization and normalizer is not None else test_data.clone()
                raw_model_pred = model(model_inputs)
                try:
                    model_pred = extract_predictions(raw_model_pred)
                except Exception:
                    if isinstance(raw_model_pred, (list, tuple, np.ndarray)):
                        model_pred = torch.tensor(raw_model_pred, device=self.device)
                    else:
                        model_pred = torch.as_tensor(raw_model_pred).to(self.device)

                # åå‘æ ‡å‡†åŒ–
                if use_normalization and normalizer is not None:
                    model_pred = normalizer.inverse_transform_labels(model_pred)

                model_mse = nn.MSELoss()(model_pred, original_test_labels).item()
                model_mae = nn.L1Loss()(model_pred, original_test_labels).item()
                
                individual_metrics.append({
                    'model_index': i,
                    'mse': model_mse,
                    'mae': model_mae,
                    'rmse': np.sqrt(model_mse)
                })
        
        metrics['individual_models'] = individual_metrics
        
        # è®¡ç®—é›†æˆå¢ç›Š
        avg_individual_mse = np.mean([m['mse'] for m in individual_metrics])
        best_individual_mse = min([m['mse'] for m in individual_metrics])
        
        metrics['avg_individual_mse'] = avg_individual_mse
        metrics['best_individual_mse'] = best_individual_mse
        metrics['ensemble_gain_from_avg'] = ((avg_individual_mse - metrics['ensemble_mse']) / avg_individual_mse) * 100
        metrics['ensemble_gain_from_best'] = ((best_individual_mse - metrics['ensemble_mse']) / best_individual_mse) * 100
        
        return metrics
    
    def optimize_weights(self, validation_data: torch.Tensor, validation_labels: torch.Tensor,
                        use_normalization: bool = True, iterations: int = 100) -> List[float]:
        """
        ä¼˜åŒ–é›†æˆæƒé‡ä»¥æœ€å¤§åŒ–æ€§èƒ½
        
        Args:
            validation_data: éªŒè¯æ•°æ®
            validation_labels: éªŒè¯æ ‡ç­¾
            use_normalization: æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–å™¨
            iterations: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
            
        Returns:
            List[float]: ä¼˜åŒ–åçš„æƒé‡
        """
        if not self.models:
            raise ValueError("é›†æˆæ¨¡å‹ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ æ¨¡å‹")
        
        print("ğŸ”§ å¼€å§‹ä¼˜åŒ–é›†æˆæƒé‡...")
        
        # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        val_data = validation_data.to(self.device)
        val_labels = validation_labels.to(self.device)
        
        # é¢„å…ˆè®¡ç®—æ‰€æœ‰æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„é¢„æµ‹
        all_predictions = []
        with torch.no_grad():
            for i, (model, normalizer) in enumerate(zip(self.models, self.normalizers)):
                # åº”ç”¨æ ‡å‡†åŒ–
                if use_normalization and normalizer is not None:
                    model_inputs = normalizer.transform_features(val_data.clone())
                else:
                    model_inputs = val_data.clone()
                raw_pred = model(model_inputs)
                try:
                    pred = extract_predictions(raw_pred)
                except Exception:
                    if isinstance(raw_pred, (list, tuple, np.ndarray)):
                        pred = torch.tensor(raw_pred, device=self.device)
                    else:
                        pred = torch.as_tensor(raw_pred).to(self.device)

                # åå‘æ ‡å‡†åŒ–
                if use_normalization and normalizer is not None:
                    pred = normalizer.inverse_transform_labels(pred)

                all_predictions.append(pred)
        
        # åˆå§‹åŒ–æƒé‡
        weights = torch.ones(len(self.models), requires_grad=True, device=self.device)
        optimizer = torch.optim.Adam([weights], lr=0.1)
        
        best_loss = float('inf')
        best_weights = weights.clone().detach().cpu().numpy()
        
        # ä¼˜åŒ–å¾ªç¯
        for iteration in range(iterations):
            optimizer.zero_grad()
            
            # ç¡®ä¿æƒé‡ä¸ºæ­£å¹¶å½’ä¸€åŒ–
            normalized_weights = nn.functional.softmax(weights, dim=0)
            
            # è®¡ç®—åŠ æƒé¢„æµ‹
            weighted_preds = [pred * w for pred, w in zip(all_predictions, normalized_weights)]
            ensemble_pred = torch.stack(weighted_preds).sum(dim=0)
            
            # è®¡ç®—æŸå¤±
            loss = nn.MSELoss()(ensemble_pred, val_labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # è®°å½•æœ€ä½³æƒé‡
            if loss.item() < best_loss:
                best_loss = loss.item()
                best_weights = normalized_weights.clone().detach().cpu().numpy()
            
            # æ‰“å°è¿›åº¦
            if (iteration + 1) % 10 == 0:
                print(f"  è¿­ä»£ {iteration+1}/{iterations}, æŸå¤±: {loss.item():.6f}")
        
        # è½¬æ¢ä¸ºPythonåˆ—è¡¨å¹¶ç¡®ä¿å½’ä¸€åŒ–
        best_weights = best_weights.tolist()
        total = sum(best_weights)
        best_weights = [w / total for w in best_weights]
        
        print(f"âœ… æƒé‡ä¼˜åŒ–å®Œæˆ")
        print(f"   æœ€ä½³æŸå¤±: {best_loss:.6f}")
        print(f"   ä¼˜åŒ–æƒé‡: {best_weights}")
        
        # æ›´æ–°æ¨¡å‹æƒé‡
        self.model_weights = best_weights
        
        return best_weights
    
    def save_ensemble(self, save_path: str) -> bool:
        """
        ä¿å­˜é›†æˆæ¨¡å‹
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # ä¿å­˜é›†æˆé…ç½®
            ensemble_data = {
                'ensemble_info': self.ensemble_info,
                'model_weights': self.model_weights,
                'save_time': datetime.now().isoformat(),
                'torch_version': torch.__version__
            }
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            config_path = save_path.replace('.pth', '.json')
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(ensemble_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… é›†æˆé…ç½®å·²ä¿å­˜è‡³: {config_path}")
            
            # è¿™é‡Œæˆ‘ä»¬ä¸ä¿å­˜å®Œæ•´çš„æ¨¡å‹ï¼Œåªä¿å­˜é…ç½®
            # åœ¨åŠ è½½æ—¶ï¼Œä¼šæ ¹æ®è·¯å¾„é‡æ–°åŠ è½½å„ä¸ªæ¨¡å‹
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜é›†æˆæ¨¡å‹å¤±è´¥: {str(e)}")
            return False
    
    def load_ensemble(self, config_path: str, model_dir: str = None) -> bool:
        """
        åŠ è½½é›†æˆæ¨¡å‹é…ç½®
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            model_dir: æ¨¡å‹æ–‡ä»¶ç›®å½•ï¼ˆå¦‚æœä¸é…ç½®æ–‡ä»¶ä¸åŒï¼‰
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            # è¯»å–é…ç½®æ–‡ä»¶
            with open(config_path, 'r', encoding='utf-8') as f:
                ensemble_data = json.load(f)
            
            # é‡ç½®å½“å‰é›†æˆ
            self.models = []
            self.model_weights = []
            self.normalizers = []
            self.model_metadatas = []
            
            # åŠ è½½é›†æˆä¿¡æ¯
            self.ensemble_info = ensemble_data.get('ensemble_info', {})
            self.ensemble_strategy = self.ensemble_info.get('strategy', 'weighted_average')
            
            print(f"âœ… åŠ è½½é›†æˆé…ç½®æˆåŠŸ")
            print(f"   é›†æˆç­–ç•¥: {self.ensemble_strategy}")
            print(f"   æ¨¡å‹æ•°é‡: {self.ensemble_info.get('models_count', 0)}")
            
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é¢å¤–çš„æ¨¡å‹è·¯å¾„ä¿¡æ¯
            # åœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨æ­£ç¡®çš„ä½ç½®
            
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½é›†æˆæ¨¡å‹å¤±è´¥: {str(e)}")
            return False
    
    def generate_ensemble_report(self, test_data: torch.Tensor = None, 
                               test_labels: torch.Tensor = None, 
                               use_normalization: bool = True,
                               save_path: str = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆé›†æˆæ¨¡å‹æ€§èƒ½æŠ¥å‘Š
        
        Args:
            test_data: æµ‹è¯•æ•°æ®
            test_labels: æµ‹è¯•æ ‡ç­¾
            use_normalization: æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–å™¨
            save_path: ä¿å­˜æŠ¥å‘Šçš„è·¯å¾„
            
        Returns:
            Dict: æŠ¥å‘Šæ•°æ®
        """
        report = {
            'ensemble_info': self.ensemble_info,
            'model_details': []
        }
        
        # æ”¶é›†æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
        for i, (model, weight, metadata) in enumerate(zip(self.models, self.model_weights, self.model_metadatas)):
            model_report = {
                'index': i,
                'weight': weight,
                'metadata': metadata,
                'model_info': metadata.get('model_info', {})
            }
            report['model_details'].append(model_report)
        
        # å¦‚æœæä¾›äº†æµ‹è¯•æ•°æ®ï¼Œè¿›è¡Œè¯„ä¼°
        if test_data is not None and test_labels is not None:
            metrics = self.evaluate(test_data, test_labels, use_normalization)
            report['evaluation_metrics'] = metrics
        
        # ä¿å­˜æŠ¥å‘Š
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"âœ… é›†æˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {save_path}")
        
        return report
    
    def plot_performance_comparison(self, metrics: Dict[str, Any], save_path: str = None) -> None:
        """
        ç»˜åˆ¶é›†æˆæ¨¡å‹ä¸å•ä¸ªæ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒå›¾
        
        Args:
            metrics: è¯„ä¼°æŒ‡æ ‡
            save_path: ä¿å­˜å›¾è¡¨çš„è·¯å¾„
        """
        # æå–æ•°æ®
        individual_mses = [m['mse'] for m in metrics['individual_models']]
        ensemble_mse = metrics['ensemble_mse']
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(12, 6))
        
        # ç»˜åˆ¶å•ä¸ªæ¨¡å‹æ€§èƒ½
        plt.bar(range(len(individual_mses)), individual_mses, 
                color='skyblue', label='å•ä¸ªæ¨¡å‹')
        
        # ç»˜åˆ¶é›†æˆæ¨¡å‹æ€§èƒ½
        plt.bar(len(individual_mses), ensemble_mse, 
                color='salmon', label='é›†æˆæ¨¡å‹')
        
        # æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
        plt.xlabel('æ¨¡å‹')
        plt.ylabel('MSEæŸå¤±')
        plt.title('é›†æˆæ¨¡å‹ä¸å•ä¸ªæ¨¡å‹æ€§èƒ½æ¯”è¾ƒ')
        plt.xticks(range(len(individual_mses) + 1), 
                  [f'æ¨¡å‹{i}' for i in range(len(individual_mses))] + ['é›†æˆ'])
        plt.legend()
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # æ˜¾ç¤ºå¢ç›Šä¿¡æ¯
        plt.figtext(0.5, 0.01, 
                   f"é›†æˆå¢ç›Šï¼ˆç›¸å¯¹äºå¹³å‡ï¼‰: {metrics['ensemble_gain_from_avg']:.2f}% | "
                   f"é›†æˆå¢ç›Šï¼ˆç›¸å¯¹äºæœ€ä½³ï¼‰: {metrics['ensemble_gain_from_best']:.2f}%",
                   ha="center", fontsize=10, bbox={"facecolor":"orange", "alpha":0.3, "pad":5})
        
        # ä¿å­˜å›¾è¡¨
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… æ€§èƒ½æ¯”è¾ƒå›¾å·²ä¿å­˜è‡³: {save_path}")
        
        plt.close()


def create_ensemble_from_directory(model_dir: str, output_dir: str = None, 
                                  strategy: str = 'weighted_average',
                                  optimize_weights: bool = True,
                                  val_data: Optional[torch.Tensor] = None,
                                  val_labels: Optional[torch.Tensor] = None) -> EWPINNEnsembleModel:
    """
    ä»ç›®å½•ä¸­çš„æ¨¡å‹åˆ›å»ºé›†æˆæ¨¡å‹
    
    Args:
        model_dir: åŒ…å«æ¨¡å‹æ–‡ä»¶çš„ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        strategy: é›†æˆç­–ç•¥
        optimize_weights: æ˜¯å¦ä¼˜åŒ–æƒé‡
        val_data: ç”¨äºä¼˜åŒ–æƒé‡çš„éªŒè¯æ•°æ®
        val_labels: ç”¨äºä¼˜åŒ–æƒé‡çš„éªŒè¯æ ‡ç­¾
        
    Returns:
        EWPINNEnsembleModel: åˆ›å»ºçš„é›†æˆæ¨¡å‹
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = os.path.join(model_dir, 'ensemble')
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºé›†æˆæ¨¡å‹
    ensemble = EWPINNEnsembleModel()
    
    # è®¾ç½®é›†æˆç­–ç•¥
    ensemble.set_ensemble_strategy(strategy)
    
    # æ·»åŠ æ¨¡å‹
    added_count = ensemble.add_models_from_directory(model_dir)
    
    if added_count == 0:
        print("âŒ æœªæ·»åŠ ä»»ä½•æ¨¡å‹ï¼Œé›†æˆåˆ›å»ºå¤±è´¥")
        return None
    
    # ä¼˜åŒ–æƒé‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if optimize_weights and val_data is not None and val_labels is not None:
        ensemble.optimize_weights(val_data, val_labels)
    
    # ä¿å­˜é›†æˆé…ç½®
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ensemble_path = os.path.join(output_dir, f'ewp_pinn_ensemble_{timestamp}.json')
    ensemble.save_ensemble(ensemble_path)
    
    print(f"\nâœ… é›†æˆæ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"   æ¨¡å‹æ•°é‡: {added_count}")
    print(f"   é›†æˆç­–ç•¥: {strategy}")
    print(f"   é…ç½®ä¿å­˜: {ensemble_path}")
    
    return ensemble


def main():
    """
    ç¤ºä¾‹ï¼šåˆ›å»ºå’Œè¯„ä¼°EWPINNé›†æˆæ¨¡å‹
    """
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸš€ EWPINNé›†æˆå­¦ä¹ æ¼”ç¤º")
    
    # åˆ›å»ºé›†æˆæ¨¡å‹
    ensemble = EWPINNEnsembleModel()
    
    # è®¾ç½®é›†æˆç­–ç•¥
    ensemble.set_ensemble_strategy('weighted_average')
    
    print("\nğŸ“‹ é›†æˆå­¦ä¹ æ¡†æ¶å·²å‡†å¤‡å°±ç»ª")
    print("   ä½¿ç”¨æ–¹æ³•:")
    print("   1. é€šè¿‡ add_model() æˆ– add_models_from_directory() æ·»åŠ æ¨¡å‹")
    print("   2. ä½¿ç”¨ set_ensemble_strategy() é€‰æ‹©é›†æˆç­–ç•¥")
    print("   3. é€šè¿‡ optimize_weights() ä¼˜åŒ–é›†æˆæƒé‡")
    print("   4. ä½¿ç”¨ evaluate() è¯„ä¼°é›†æˆæ€§èƒ½")
    print("   5. é€šè¿‡ generate_ensemble_report() ç”ŸæˆæŠ¥å‘Š")
    

if __name__ == "__main__":
    main()